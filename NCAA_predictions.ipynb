{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA March Madness Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset shown below is a mix of ESPN and Ken Pom's basketball statistics. Quite a bit of work has already been done to clean and merge the data, as well as find the best predictors. Using this data, I will try to identify the optimal statistical method to predict the outcome of future games.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NCAA = pd.read_csv(r\"C:/Users/ia767/Documents/NCAA_big.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team_1</th>\n",
       "      <th>Team_2</th>\n",
       "      <th>Score_Gap</th>\n",
       "      <th>Win</th>\n",
       "      <th>RK_1</th>\n",
       "      <th>BPI_1</th>\n",
       "      <th>BPI_OFF_1</th>\n",
       "      <th>BPI_DEF_1</th>\n",
       "      <th>Wins_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Luck_2</th>\n",
       "      <th>X13_2</th>\n",
       "      <th>AdjEM_1_2</th>\n",
       "      <th>X15_2</th>\n",
       "      <th>OppO_2</th>\n",
       "      <th>X17_2</th>\n",
       "      <th>OppD_2</th>\n",
       "      <th>X19_2</th>\n",
       "      <th>AdjEM_2_2_2</th>\n",
       "      <th>X21_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>UMBC</td>\n",
       "      <td>-20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>269</td>\n",
       "      <td>102.7</td>\n",
       "      <td>267</td>\n",
       "      <td>107.1</td>\n",
       "      <td>259</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>Kansas State</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>31</td>\n",
       "      <td>9.39</td>\n",
       "      <td>34</td>\n",
       "      <td>111.0</td>\n",
       "      <td>14</td>\n",
       "      <td>101.6</td>\n",
       "      <td>59</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Davidson</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>318</td>\n",
       "      <td>2.11</td>\n",
       "      <td>104</td>\n",
       "      <td>105.6</td>\n",
       "      <td>116</td>\n",
       "      <td>103.5</td>\n",
       "      <td>91</td>\n",
       "      <td>1.33</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>-21</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>140</td>\n",
       "      <td>105.1</td>\n",
       "      <td>145</td>\n",
       "      <td>105.2</td>\n",
       "      <td>147</td>\n",
       "      <td>3.87</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UMBC</td>\n",
       "      <td>Kansas State</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>31</td>\n",
       "      <td>9.39</td>\n",
       "      <td>34</td>\n",
       "      <td>111.0</td>\n",
       "      <td>14</td>\n",
       "      <td>101.6</td>\n",
       "      <td>59</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Team_1        Team_2  Score_Gap  Win  RK_1  BPI_1  \\\n",
       "0           1   Virginia          UMBC        -20    0     2   20.2   \n",
       "1           2  Creighton  Kansas State        -10    0    24   12.2   \n",
       "2           3   Kentucky      Davidson          5    1    19   12.9   \n",
       "3           4    Arizona       Buffalo        -21    0    26   11.9   \n",
       "4           5       UMBC  Kansas State         -7    0   156    0.7   \n",
       "\n",
       "   BPI_OFF_1  BPI_DEF_1  Wins_1  ...    Luck_2  X13_2  AdjEM_1_2  X15_2  \\\n",
       "0        7.0       13.2      31  ...     0.125      2      -4.38    269   \n",
       "1        8.1        4.1      21  ...     0.071     31       9.39     34   \n",
       "2        7.0        5.9      26  ...    -0.063    318       2.11    104   \n",
       "3        9.4        2.5      27  ...     0.006    158      -0.06    140   \n",
       "4       -0.2        0.9      25  ...     0.071     31       9.39     34   \n",
       "\n",
       "   OppO_2  X17_2  OppD_2  X19_2  AdjEM_2_2_2  X21_2  \n",
       "0   102.7    267   107.1    259        -3.55    277  \n",
       "1   111.0     14   101.6     59        -6.50    324  \n",
       "2   105.6    116   103.5     91         1.33    121  \n",
       "3   105.1    145   105.2    147         3.87     62  \n",
       "4   111.0     14   101.6     59        -6.50    324  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCAA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two variables below were selected elsewhere using forward subset selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = NCAA['Win']\n",
    "X = NCAA[[\"BPI_DEF_1\", \"Wins_2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAF3CAYAAABjZBdpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3X2cXHdd9//Xe+9ms0k3LbDB0qa2\nKBQIskCXgmBUCi6RVqFe3hQDVu4qisqNekHBxw/h+qn4Q4t3iFZaKBpALyBaKZStFS4ClJYE2NJQ\naEsBU1vYcNVmk2x29mY+vz/OSbq7ndnM7M7MOTPn/Xw85jE73zln5vOdc/bsZ7/zvVFEYGZmZmZm\n9evJOgAzMzMzs07jJNrMzMzMrEFOos3MzMzMGuQk2szMzMysQU6izczMzMwa5CTazMzMzKxBTqLN\nzMzMzBrkJNrMzMzMrEFOos3MzMzMGuQk2szMzMysQX1ZB1CPRzziEXH22WdnHYaZWcP27dv3/YgY\nyTqOdvI128w6Wb3X7Y5Ios8++2z27t2bdRhmZg2T9J2sY2g3X7PNrJPVe912dw4zMzMzswY5iTYz\nMzMza5CTaDMzMzOzBjmJNjMzMzNrkJNoMzMzM7MGOYk2MzMzM2uQk2gzMzMzswY5iTYzMzMza5CT\naDMzMzOzBjmJNjMzMzNrUEcs+90s5f0HmJ2YZHFqmt4twwyOj1LatjXrsMzMrEV83TezVilMS3R5\n/wGO7tpD5dAMGt5A5dAMR3ftobz/QNahmZlZC/i6b2atVJgkenZiEg30ocEBJCX3A33MTkxmHZqZ\nmbWAr/tm1kqFSaIXp6ah1L+8sNTP4sHpbAIyM7OW8nXfzFqpMEl075ZhKM8vLyzP0zsynE1AZmbW\nUr7um1krFSaJHhwfJeYWiNk5IiK5n1tgcHw069DMzKwFfN03s1YqTBJd2raVjTu307N5iDh8jJ7N\nQ2zcud2jtM3MupSv+2bWSoWa4q60basvnmZmBeLrvpm1SmFaos3MzMzMmsVJtJmZmZlZg5xEm5mZ\nmZk1yEm0mZmZmVmDnESbmZmZmTXISbSZmZmZWYOcRJuZmZmZNchJtJlZl5M0KOkWSZOS9kt6a1r+\nPknfkvSV9PbkGvtfKunO9HZpe6M3M8unQi22YmZWUGXggog4Iqkf+KykT6TP/V5EfLjWjpIeBrwF\nGAMC2Cfp2oj475ZHbWaWY26JNjPrcpE4kj7sT29R5+7PA26IiPvTxPkGYEcLwjQz6yhOos3MCkBS\nr6SvAFMkSfHN6VN/KOlWSe+UVKqy6xnAgSWP70nLzMwKzUm0mVkBRMRiRDwZOBM4X9ITgcuBxwFP\nAx4GvKHKrqr2cg/ZSLpM0l5Jew8ePNjEyM3M8slJtJlZgUTEA8CngR0RcV/a1aMMvBc4v8ou9wBb\nlzw+E7i3yuteGRFjETE2MjLSgsjNzPLFSbSZWZeTNCLp1PTnDcBzga9LOj0tE/BC4LYqu38SGJd0\nmqTTgPG0zMys0Dw7h5lZ9zsduEZSL0njyT9HxMck/YekEZIuG18BXgUgaQx4VUS8IiLul/S/gC+m\nr/W2iLg/gzqYmeWKk2gzsy4XEbcCT6lSfkGN7fcCr1jy+Grg6pYFaGbWgZxEm9kJ5f0HmJ2YZHFq\nmt4twwyOj1LatvXkO5qZmRWM+0SbGZAk0Ed37aFyaAYNb6ByaIaju/ZQ3n/g5DubmZkVjJNoMwNg\ndmISDfShwQEkJfcDfcxOTGYdmpmZWe44iTYzABanpqHUv7yw1M/iwelsAjIzM8uxliXRkq6WNCXp\ntiVl75D09XR1rN3Hp1wys+z1bhmG8vzywvI8vSPD2QRkZmaWY61siX4fsGNF2Q3AEyPiScAdJKtl\nmVkODI6PEnMLxOwcEZHczy0wOD6adWhmZma507IkOiI+A9y/omwiIhbSh18gWfnKzHKgtG0rG3du\np2fzEHH4GD2bh9i4c7tn5zAzM6siyynuXgb8U4bvb2YrlLZtddJsZmZWh0wGFkp6M7AA7Fplm8sk\n7ZW09+DBg+0LzszMzMzsJNqeREu6FLgI2BkRUWu7iLgyIsYiYmxkZKR9AZqZmZmZnURbu3NI2gG8\nAfiJiJhp53ubmZmZmTVLK6e4+yBwE3CupHskvRz4a+AU4AZJX5H0t616fzMzMzOzVmlZS3REvKhK\n8VWtej8zMzMzs3bxioVmZmZmZg1yEm1mZmZm1iAn0WZmZmZmDXISbWZmZmbWICfRZmZmZmYNchJt\nZmZmZtYgJ9FmZmZmZg1yEm1mZmZm1iAn0WZmZmZmDXISbWZmZmbWICfRZmZmZmYNchJtZmZmZtag\nvqwDMDMz6ybl/QeYnZhkcWqa3i3DDI6PUtq2NeuwTqoZcXdq3c3Wwi3RZmZmTVLef4Cju/ZQOTSD\nhjdQOTTD0V17KO8/kHVoq2pG3J1ad7O1chJtZmbWJLMTk2igDw0OICm5H+hjdmIy69BW1Yy4O7Xu\nZmvlJNrMzKxJFqemodS/vLDUz+LB6WwCqlMz4u7UuputlZNoMzOzJundMgzl+eWF5Xl6R4azCahO\nzYi7U+tutlZOos3MzJpkcHyUmFsgZueIiOR+boHB8dGsQ1tVM+Lu1LqbrZWTaDMzsyYpbdvKxp3b\n6dk8RBw+Rs/mITbu3J77GSqaEXen1t1srTzFnZlZl5M0CHwGKJFc9z8cEW+RtAsYA+aBW4Bfi4j5\nKvsvAl9NH/5nRPxseyLvTKVtWzsycWxG3J1ad7O1cBJtZtb9ysAFEXFEUj/wWUmfAHYBL063+QDw\nCuDdVfY/FhFPbk+oZmadwUm0mVmXi4gAjqQP+9NbRMTHj28j6RbgzAzCMzPrSO4TbWZWAJJ6JX0F\nmAJuiIiblzzXD7wEuL7G7oOS9kr6gqQXtiFcM7PccxJtZlYAEbGYdsk4Ezhf0hOXPP03wGciYk+N\n3c+KiDHgl4E/l/RDKzeQdFmaaO89ePBg0+M3M8sbJ9FmZgUSEQ8AnwZ2AEh6CzACvH6Vfe5N7+9O\n931KlW2ujIixiBgbGRlpfuBmZjnjJNrMrMtJGpF0avrzBuC5wNclvQJ4HvCiiKjU2Pc0SaX050cA\nzwK+1p7IzczyywMLzcy63+nANZJ6SRpP/jkiPiZpAfgOcJMkgI9GxNskjQGviohXAI8H/k5SJd33\n7RHhJNrMCs9JtJlZl4uIW6neBaPq34CI2Esy3R0R8XngR1oaoJlZB3ISbWZmhVPef4DZiUkWp6bp\n3TLM4PhoVy4S0sp6HrluH7PXTxIzZTRUYnDHKJsuPK8pr231K8q5nEfuE21mZoVS3n+Ao7v2UDk0\ng4Y3UDk0w9FdeyjvP5B1aE3VynoeuW4fx3bfQpTnob+XKM9zbPctHLluXxMit3oV5VzOKyfRZmZW\nKLMTk2igDw0OICm5H+hjdmIy69CaqpX1nL1+Enp6UF8P6hHq64GenqTc2qYo53JeOYk2M7NCWZya\nhlL/8sJSP4sHp7MJqEVaWc+YKUOPlhf2iDhWXvdrW/2Kci7nlZNoMzMrlN4tw1CeX15Ynqd3ZDib\ngFqklfXUUAkqsbywEmhDad2vbfUryrmcV06izcysUAbHR4m5BWJ2johI7ucWGBwfzTq0pmplPQd3\njEKlQixUiEoQCxWoVJJya5uinMt55STazMwKpbRtKxt3bqdn8xBx+Bg9m4fYuHN7181o0Mp6brrw\nPDZcfD4q9cPCIir1s+Hi8z07R5sV5VzOK09xZ2ZmhVPatrUQiUYr67npwvOcNOdAUc7lPHJLtJmZ\nmZlZg5xEm5mZmZk1yEm0mZmZmVmDWpZES7pa0pSk25aUPUzSDZLuTO9Pa9X7m5mZmZm1Sitbot8H\n7FhR9kbgxoh4DHBj+tjMzMzMrKO0LImOiM8A968ofgFwTfrzNcALW/X+ZmZmZmat0u4+0Y+MiPsA\n0vstbX5/MzMzM7N1y+3AQkmXSdorae/BgwezDsfMzMzM7IR2J9Hfk3Q6QHo/VWvDiLgyIsYiYmxk\nZKRtAZqZmZmZnUy7Vyy8FrgUeHt6/69tfn8zMzPLufL+A8xOTLI4NU3vlmEGx0e9Kp/lTiunuPsg\ncBNwrqR7JL2cJHn+KUl3Aj+VPjYzMzMDkgT66K49VA7NoOENVA7NcHTXHsr7D2QdmtkyLWuJjogX\n1XjqOa16TzMzM+tssxOTaKAPDQ4kBen97MSkW6MtV3I7sNDMzMyKZ3FqGkr9ywtL/SwenM4mILMa\nnESbmZlZbvRuGYby/PLC8jy9I8PZBGRWg5NoMzMzy43B8VFiboGYnSMikvu5BQbHR7MOzWwZJ9Fm\nZmaWG6VtW9m4czs9m4eIw8fo2TzExp3b3R/acqfdU9yZmZmZraq0bauTZss9t0SbmZmZmTXISbSZ\nmZmZWYOcRJuZmZmZNchJtJmZmZlZg046sFDSk6oUHwIORESl+SGZWTOV9x9gdmKSxalpercMMzg+\n6gE7HUbSXwFR6/mI+O02hmNmZtTXEn0VsA94P/APwF5gN3CnJC/hbZZj5f0HOLprD5VDM2h4A5VD\nMxzdtYfy/gNZh2aN2UtyHR4Engrcmd6eDCxmGJeZWWHVk0TfCZwXEU+OiFHgPOArwPOAP2tlcGa2\nPrMTk2igDw0OICm5H+hjdmIy69CsARFxTURcAzwGeHZE/FVE/BXwHJJE2szM2qyeJPrxEXHr8QcR\n8VXgqRFxV+vCMrNmWJyahlL/8sJSP4sHp7MJyNbrUcApSx5vSstWJWlQ0i2SJiXtl/TWtPwcSTdL\nulPSP0kaqLH/5ZLukvQNSc9rSk3MzDpcPYutfDPtj/eh9PEvAXdJKgELLYvMzNatd8swlUMzMLgk\nNyrP0zsynF1Qth5vB74s6VPp458A/qCO/crABRFxRFI/8FlJnwBeD7wzIj4k6W+BlwPvXrqjpCcA\nlwDbSBL2f5f02IhwN5KCyGJcRZHHchS57p2mnpboXwHuAd4IXA7cC1xKkkC7T7RZjg2OjxJzC8Ts\nHBGR3M8tMDg+mnVo1iBJAv4deDrJuJTdwI+m3TxWFYkj6cP+9BbABcCH0/JrgBdW2f0FwIciohwR\n3wLuAs5fT12sc2QxrqLIYzmKXPdOdNIkOiJmIuJPIuJnIuKiiHh7RByNiMWIONSOIM1sbUrbtrJx\n53Z6Ng8Rh4/Rs3mIjTu3u1WjA0VEAP8SEd+NiH9Nb9+td39JvZK+AkwBNwDfBB6IiOPfKN4DnFFl\n1zOApX/Ba21nXSiLcRVFHstR5Lp3onqmuHsG8BbgB5duHxGPbWFcZtYkpW1bnTR3jy9IelpEfLHR\nHdPuF0+WdCpJK/bjq21WpUz1bCfpMuAygLPOOqvR8CynFqem0fCG5YUtHleRxXvmRZHr3onq6RP9\nXuB/kkyv5D5wZmbZeTbwa5K+AxwlSXAjIqrN519VRDwg6dPAM4BTJfWlrdFnknTXW+keYOl/YVW3\ni4grgSsBxsbGas5pbZ0li3EVRR7LUeS6d6J6+kRPR8S/RcS9EfG947eWR2ZmZiv9NPBDJH2Zfwa4\nKL1flaSRtAUaSRuA5wK3A58Cfj7d7FLgX6vsfi1wiaSSpHNIptm7ZZ31sA6RxbiKIo/lKHLdO1E9\nSfR/SPpjSU+T9KTjt5ZHZmZmy0TEd4BTSRLnnwFOTctO5nTgU5JuBb4I3BARHwPeALxe0l3Aw0kW\n10LSz0p6W/qe+4F/Br4GXA+82jNzFEcW4yqKPJajyHXvRErGqqyygbSnSnFExI+3JqSHGhsbi717\n97br7czMmkbSvogYa9JrvQZ4JfDRtOhi4Mp04ZXc8DXbzDpZvdftk/aJjojtzQnJzMzW6eXA0yPi\nKICkPwFuAnKVRJuZFUHNJFrSiyLig5J+u9rzEfGXrQvLzMyqEMsHeC9SffYMMzNrsdVaok9L70eq\nPOeR12Zm7fde4GZJu9PHLyTtx2xmZu1VM4mOiL9Jf7wuIr6w9Ll07mgzM2ujiLginZ7ux0haoF8a\nEV/ONiozs2KqZ57ovwGeuqLsXcB5zQ/HzMxqSRsw9kfEl9LHp0h6ekTcnHFoZmaFs1qf6POBHwVG\nVvSLHgb6Wx2YmZk9xLtZ3qhxtEqZmZm1wWot0RuBR6TbLO0XfRj4hVYGZWZmVSmWzEsaERVJ9Xyj\naGZmTbZan+hPkUzO/96IuLuNMeVaef8BZicmWZyapnfLMIPjo54E3TqSz+X65Oxzujv9ZvDd6ePf\nAHx9NjPLQF3LfqcrFl4raeL4reWR5VB5/wGO7tpD5dAMGt5A5dAMR3ftobz/QNahmTXE53J9cvg5\nvQp4JvBfwD3A04HLsgrGzKzI6vka8B+B3SQrY70auBT4biuDyqvZiUk00IcGB5KC9H52YtIteNZR\nfC7XJ2+fU0RMAZe0/Y2tq9T6diWLb12a8Z45+7bICqSeluiRiPg7YC4ibiRJos9vbVj5tDg1DaUV\nYypL/SwenM4mILM18rlcn7x9TpIeK+lGSbelj58k6fczCcY6Uq1vV45ct6/t37o045ueHH5bZAVS\nTxI9n95/V9LzgCcChfwXr3fLMJTnlxeW5+kdGc4mILM18rlcnxx+Tn8PXE56XY6IW3HLtDVg6bcr\nkpL7gT5mr69RPjHZ/lgaeM9mvIbZWtXTneOPJG0Gfpdkfuhh4PdaGlVODY6PcnTXnuRBqR/K88Tc\nAoPjo9kGllN5+YotL3Hkic/l6laeK72PPZ3Fz30jeTIfn9NQRNwiLVvpeyGrYKzzLE5No+ENywtL\n/cRMGR512kPKW/mtS61YGnnPZryG2VqdtCU6Iq6NiEMRcWtEbI+IUeATbYgtd0rbtrJx53Z6Ng8R\nh4/Rs3mIjTu3Fz4hqyYvX7HlJY688bn8UNXOlbnPfYOBZ52bp8/p+5J+CAgAST8P3JdVMNZ5an27\noqFS2791acY3PTn8tsgKZNWWaEmPBE4HbouIBUmPAH4beDlwRhviy53Stq2FTjTqlZcBWXmJI498\nLi9X61xZvOM+Nr/uogwjW+bVwJXA4yT9F/At4MXZhmSdpOa3UDtGmWvzty7N+EbM36pZlmq2REv6\nLeBrJH3wbpa0E/gGcBrJtEpmNeVlQFZe4rD864RzJSLujojnkiyA9biI+LGI+HbGYVkHqfUt1KYL\nz2v7t1PN+EbM36pZllZrif514NyI+L6ks4E7gGdHxOfaEZh1tt4tw1QOzZxozQMy+YotL3FY/uX9\nXJHUC5wWEd+PiKOSBiS9Enh9RDw+6/isc9T6FiqLb6ea8Z7+Vs2yslqf6NmI+D5A2tJxhxNoq9fg\n+Cgxt0DMzhERyX0GX7HlJQ7LvzyfK5IuAe4HbpX0fyQ9m2SlwucDOzMNzsysoFZriT5T0hVLHm9Z\n+jgiXr/WN5X0OuAVJINjvgq8NCJm1/p6lj+lbVth5/ZkpoOD0/SOZDMrRl7isPzL+bny+8B5EXGX\npKcCNwGXRMTujOMyMyus1ZLoy0/yeE0knUEyOPEJEXFM0j+TzHP6vma8vuVHXr5iy0scln85Plfm\nIuIugIj4kqRvOYE2M8tWzSQ6Iq5q8ftukDQPDAH3tvC9zMw63RZJS7/927T0cURcUWUfMzNroXoW\nW2mqiPgvSX8K/CdwDJiIiIl2x2HWqY5ct4/Z6yeJmTIaKjG4Y5RNF56XdVjWWn8PnLLKYzMza7O2\nJ9GSTgNeAJwDPAD8b0kvjoh/XLHdZcBlAGeddVa7wzTLpSPX7ePY7lugpwf6e4nyfPIYnEh3sYh4\na9YxmJnZciddsbAFngt8KyIORsQ88FHgmSs3iogrI2IsIsZGRkbaHqRZHs1ePwk9PaivB/UI9fVA\nT09SbmZmZm1z0iRa0g9L+qSkyfTxkyStZ5DhfwLPkDQkScBzgNvX8XpmhREzZejR8sIeEcfK2QRk\nZmZWUPV053gP8CbgXenjrwIfBP54LW8YETdL+jDwJWAB+DLJMrZmdhIaKhHl+eWJdCXQhlJ2QZmZ\nWU3l/QeSqTOnpundkqupM22d6kmiN0bE55NGY4iISGfVWLOIeAvwlvW8hlmr5PmCN7hjlGO7byEW\nSBLpSkClwuCO7BcEsdaTVAL+B3A2S67fEfG2rGIys9rK+w9wdNceNNCHhjdQOTTD0V17wEuTd4V6\n+kT/X0nnkCyMgqQXAt9taVRmGTl+wascmll2wSvvP5B1aEAyeHDDxeejUj8sLKJSPxsuPt+DCovj\nX0kGZi8AR5fczCyHZicmkwR6cABJyf1AH7MTHsfSDeppif5N4CrgcZK+A9wHvKilUZllZOkFD4D0\nfnZiMjetBpsuPM9Jc3GdGRE7sg7CzOqzODWNhjcsLyz1s3hwOpuArKlOmkSnq2RdIGkzoIh4oPVh\nmWXDFzzLuc9L+pGI+GrWgZjZyfVuGaZyaOZEgwwA5Xl6R4azC8qapp7ZOX5T0nBEHALeLukWSc9p\nQ2xmbde7ZRjKK7r8+4Jn+fFjwD5J35B0q6SvSro166DMrLrB8VFiboGYnSMikvu5BQbHPY6lG9TT\nneOyiPhrSePAmcCvk8ym4e+TresMjo8mgz4ASv1QnvcFL2fyPPCzDX466wDMrH6lbVth5/bkmnVw\nmt6Rwl2zulo9SXSk9z8NvDci9knKYpEWs5bzBS/fijrSPf02cBo4nHUsZtaY0ratXX19KrJ6kuhJ\nSR8HHgu8WdImHkyszbqOL3j51QkDP1vkA8BFwD6S6+/SFXcCePRqO0vaCrwf+AGgAlwZEX8h6Z+A\nc9PNTgUeiIgnV9n/2yQJ/CKwEBFj66qNmVkXqCeJfilJ1427ImJG0iOAl7c2LDOzhyrqwM+IuCi9\nP2eNL7EA/E5EfEnSKST9qm+IiF86voGkPwMOrfIaz46I76/x/c3Muk49s3MsSvpP4Icl1ZN0m5m1\nRFFHukv6F+BzwOeBL0bEXCP7R8R9JNOTEhGHJd0OnAF8LX19Ab8IXNDMuM3MutlJk2JJfwS8GPg6\nyVd5kHx9+PwWxmXWNEUZiNbKeublMyzwwM/3AM8E/hB4kqSv82BS/fmI+F69LyTpbOApwM1LircD\n34uIO2vsFsCEpAD+LiKurPK6lwGXAZx11ln1hmNm1rEUsXr3ZknfAEYjYrY9IT3U2NhY7N27N6u3\ntw62dCDa0qRrY5cNRGtlPfP2GZ5I6Dtk4Kekfc3sQyyplyQJ/kngVcA5EdFb576bgP8D/GFEfHRJ\n+btJuuz9WY39HhUR90raAtwA/FZEfKbW+/iabWadrN7rdj3dM75FfcuDm+VOUQaitbKeefsMizrw\nMx2P8sz09gxgEPh34KY69+8HPgLsWpFA9wE/xyrTlkbEven9lKTdwPlAzSTazKwI6kmiDwNflvTv\nQPl4YUS8vmVRmTVJUQaitbKeRfkM80zSnSSD/j4CfBL4fyPiSAP7C7gKuD0irljx9HOBr0fEPTX2\n3Qj0pH2pNwLjwNvWUA0zs65STxJ9fXoz6zhFGYjWynoW5TPMuatJWp//B/AjwBMl3QR8OSIWV90z\n8SzgJcBXJX0lLXtTRHwcuAT44NKNJT0KeE9EPB94JLA7ycPpAz4QEf6bYGaFV8/sHFdJGgDOioi7\n2hCTWdMUZSBaK+tZlM8wzyLij4//LOmxJF06Xglsl3QwIn7iJPt/luVzSy997lerlN1LOng8Iu4G\nfLDNzFaoZ3aOC4ErgAHgHElPBt4SERe3Ojiz9SrKCoStrGdRPsNOIOnRJP2Rn07SMj0C3J1pUE2Q\nl9lfrLosjk8j73nkun3MXj9JzJTRUInBHaNsurBmF39bJ/++Pqie2Tn2Ac8BPhURT0nLvhoRP9KG\n+ACP9DazztWM2TnSwXzPIOkXfRPp9HYR8bUmhNh0jVyz8zb7iy2XxfFp5D2PXLePY7tvgZ4e6BFU\nAioVNlx8vhPpFijK72u91+16Zt2Yj4gHVpR52W8zs/Z5L/AjEfG4iHhpRLwnrwl0o5bO/iIpuR/o\nY3ZiMuvQjGyOTyPvOXv9JPT0oL4e1CPU1wM9PUm5NZ1/X5erJ4m+XdIvAj2SzpH058AXWhyXmZml\nIuLabl1ye3FqOmnRWsqzv+RGFsenkfeMmXLSAr1Uj4hj5Ydsa+vn39fl6kmif5Nk/tAK8FFgFnht\nK4MyM7Ni6N0yDOX55YWe/SU3sjg+jbynhkpJF46lKoE2lFoWX5H593W5mkm0pPelP740It4QEU9J\nb2+MiJn2hGdmZt1scHyUmFsgZueIiOTes7/kRhbHp5H3HNwxCpUKsVAhKkEsVKBSScqt6fz7utxq\nLdHnSzoDeKWkUyQNL721K0AzM0tIela64AmSXizpCkk/mHVc61HatpWNO7fTs3mIOHyMns1DXTdI\nqZNlcXwaec9NF57HhovPR6V+WFhEpX4PKmwh/74uV3N2DkmvB34dOAuYWvF0RMRZLY7tBM/OYWad\nqhmzcyx5rVtJ5mx+EvAPJKsQ/tzJ5oluN1+zzayT1XvdrjlPdLo07BWS/j4iXtnU6MxyzHNg5oOP\nQ1ULERGSXgD8RboY1qVZB2VmVkQnHVgYEa+U9AxJvwIg6WGS2tYKbdZOx+fArByaQcMbqBya4eiu\nPZT3H8g6tELxcajpsKTLgRcD10nqBfpPso+ZmbXASZNoSb8PvAX4/bRoA/CBVgZllhXPgZkPPg41\n/RJQBl4eEd8FzgDekW1IZmbFdNJlv4GfB54CfAkgIv7LAwuLKe9LvzbjNRanptHwhuWFBZ4DMys+\nDtWlifMVSx7/J/D+7CIyMyuueuaJLkcy+jAAJA21NiTLoyy+Xm/Gezb6Gp4DMx98HJaT9C1Jd0u6\nOetYzMwsUU8S/VFJ7wI2S3opMAFc3dqwLG/yvvRrs17Dc2Dmg4/DchFxTkQ8OiKennUsZmaWqGdg\n4Z8AHwOuJZla6Q8j4s9bHZjlS96Xfm3Wa3gOzHzwcahO0j/UU2ZmZq130j7Rkk4BvkvS7+7OiDjS\n8qgsd3q3DFM5NAODAw8WtmHp1/W+51peo7Rta+GTtXq1sp98I8ehQNPhbVv6IJ2dw6tKmJlloGYS\nLWkA+BvgF4Fvk7Ranynpn4FXR8R8rX2t+wyOj3J0157kQakfyvNtWfp1ve+ZRdxFcby/uQb6lvU3\np80txnmJo5XSae3eBGyQdPxvNDsWAAAgAElEQVRrFAFzwJWZBWa2To38A9yp/ywfuW4fs9dPEjNl\nNFRicMcomy48r+H6NOOzauVn2KnHZz1W687xZmATcGZEPCkingj8ILCRB6e7s4LI+9KveYq7KPIy\nDV1e4miliPjjiDgFeEdEDKe3UyLi4RFxedbxma1FIwO/O3Xu+CPX7ePY7luI8jz09xLleY7tvoUH\nrrqxofo047M6ct2+ln2GnXp81mu17hw/B/zo0u4bEXFI0quAz5PMHW0FkkU3h2a8p7tntEZepqHL\nSxztEBGXSzqDpEGjb0n5Z7KLymxtlv4DDJzodjc7MfmQa3Yj2+bJ7PWT0NOD+tI2yx4RCzD/+Tvo\n2/rwuuvTlM/q+kl6H76pJZ9hpx6f9Vq1T3S1/s8RcVhStC4kM+sEWfSTz3Mc7SDp7cAlwNeAxbQ4\nACfR1nEa+Qe4U/9Zjpky9PcuL+wRzFUaGvTejM8qZsrwqNPqfs9GdOrxWa/VunNUJJ0iaXjljXTO\naDMrrrxMQ5eXONrkYuDciHh+RPxMevvZrIMyW4tG5oPv1LnjNVSCyoqUqRLQ29NQfZrxWWmo1LLP\nsFOPz3qtlkQ/HNi/4nZben/aKvuZWQHkpb95XuJok7uB/pNuZdYBGvkHuFP/WR7cMQqVCrFQISpB\nLFSgUqH/mY9tqD5N+ax2tO4z7NTjs15KFiPMt7Gxsdi7d2/WYZiZNUzSvogYa9JrfYRkvv4bgfLx\n8oj47Wa8frP4mm31OjGjw8FpekfqnHGijm3z5MTsHMfKaEOV2TnqrE8zPqtWfoadenyqqfe67STa\nzKyFmpxEX1qtPCKuacbrN4uv2WbWyeq9bp90sZVWkHQq8B7giST9q18WETdlEYuZWaeIiGskbQDO\niohvZB2PmVmRnXTZ7xb5C+D6iHgcyVeTt2cUh5lZx5D0M8BXgOvTx0+WdG22UZmZFdNJk2hJZ6er\nFyLpxyT9RjpDx5qk+/44cBVARMxFxANrfT0zswL5A+B84AGAiPgKcE6WAZmZFVU93Tn+BXiapB8C\n3g9cB3wAuGiN7/lo4CDwXkmjwD7gNRFxdI2vZxnrtqU+a9Wn1tKttj7ddv602EK66NXSsvwPbDEz\n60L1dOeoRMQ8yQqGfx4RvwWcsY737AOeCrw7Ip4CHAXeuHIjSZdJ2itp78GDB9fxdtZK3bbUZ636\nPHDVjVWXbj1y3b6sQ+5o3Xb+tMFtkn4Z6JX0GEl/RbKCrJmZtVk9SfSCpF8AXgJ8LC1bzzyl9wD3\nRMTN6eMPkyTVy0TElRExFhFjIyMj63g7a6WlS31KSu4H+pidmMw6tDWpVZ/5z99xYulW9ShZwrWn\nJ1nS1das286fNvgtYBvJ9HYfBKaB12YakZlZQdXTneNlwG8A/19E3C3pHJKL95pExHclHZB0bjq6\n/DkkS9haB+q2pT5r1YfFStWlW+NYGXuoertodNv502oRMQO8Ob2ZmVmGTppER8RtJEn08cffAv5w\nne/7W8CudMDi3cBL1/l6lpHeLcNUDs3A4MCDhR281Get+tDbkyzV2rOkL2ol0IZS+4PMueNdNDTQ\nt6yLBlVWEey286fVJD0W+F3gbJZcvyPigqxiMjMrqppJtKQbSAas3B8RlzTzTdMR5U1ZfCAvijo4\nanB8NEmQIGmxLc+vaanPLAbtVTtmg+OjTP/Vx2F24cENB/vof+Zjmb/pDmKBJJGuBFQqyZKuBdDI\n+b20iwZwIkGenZh8yD7NOn8K5H8Df0syz/5ivTtJ2koyMPwHgApwZUT8haQ/AF5JMtgb4E0R8fEq\n++8gmZq0F3hPRLx9PZUwM+sGq7VEvyq9X1hlG6OxlrduU9q2FXZuX9dSn0eu28ex3bdAT8+yQXtA\nyxLpWscsHrZxeQINJx5vuPj8qku3drtGz+9Gumg04/wpmIWIePda9gN+JyK+JOkUYF/aUALwzoj4\n01o7SuoF3gX8FMmYli9KujYiWt4NrwiNE82qY63XKcJn6JmTHqoTjnszYsy6njWT6Ij45tLHkoZY\n/vWhOy2mGml560albVvXVc/Z6ydPDNoDkr7GC0l5qy6EtY7Z4m33nIjhhEow//k7OPWqXy/khbnR\n87vRLhrrPX8K5t8k/Qawm2RwIQARcf9qO0XEfcB96c+HJd1O/bMsnQ/cFRF3A0j6EPACWjyWpQiN\nE82qY63XmX/Wucx97htd/Rlm0QiTd53wu9OMGPNQz3oWW3mFpPuAO4DbgP3pvaUWp6aTr6KX8uCo\nmsr7D3DonR/j/ss/wKF3fow4cmx50gotH7RX65gBsCIURDKwsKAaPb8Hx0eJuQVido6ISO7dRaNZ\nLgV+j2Rau33pbW8jLyDpbOApwPEZkn5T0q2SrpZ0WpVdzgCWzjl4D+ub5rQuRZi5pVl1rPk61xfg\nM1zSCOOZkxKd8LvTjBjzUM96prh7AzAaEWdGxFkRsTUizmp1YJ2kd8twMvhsKQ+OqqravMBIML+i\ne2eLB+3VOmbAQ5euCJKBhQXV6Pld2raVjTu307N5iDh8jJ7NQ2zMUQtIJ4uIc6rcHl3v/pI2AR8B\nXpt+m/hu4IeAJ5O0VP9Ztd2qhVLltZs6t38RGieaVcdarxPHyl3/GcZMue2NMHnXCb87zYgxD/Ws\nJzO4m2QuUqvBLW/1q/qf4/AQVCrEQoWoBLFQafmgvVrHrOeJZyYbVAIiknug/5mPbVksebeW87u0\nbSubX3cRD/ujX2bz6y5yAt0kkvol/bakD6e335RU17z96XYfAXZFxEcBIuJ7EbEYERXg70m6bqx0\nD7D0AJ4J3Ltyo2bP7V+Exolm1bHW62hDqes/Qw2VTlynTyj4zEmd8LvTjBjzUM96kug3Ap+T9C5J\nVxy/tTqwTuKWt/pV+8+x95Gb0aZBVOqHhUVU6mfDxee3tD9brWP28N99Af3bH5e0PKct0P3bH8ep\nL39Oy2LJO5/fufJu4Dzgb9LbeWnZqpSsE34VcHtEXLGk/PQlm11M9a56XwQeI+mcdFrSS4Br11yD\nOhWhcaJZdaz5OjsK8BnuGG17I0zedcLvTjNizEM9FfGQb+WWbyDdTNJ37qskUyMBEBFXtTa0B42N\njcXevQ11+7OcOvTOj7Fw338TR8vE/CLq70UbS/SdfhqbX3dR1uGZNZ2kfRHRlCk9JU1GxOjJyqrs\n92PAHpZfx98EvIikK0cA3wZ+LSLuk/Qokqnsnp/u/3zgz0mmuLs6IlZdK6BZ1+wTI++7eOaWZtWx\n1usU4TM8MTtHwWZOWk0nHPdmxNiqetZ73a4nib4pIn503RGtg5Po7rFsJPWS+ZZb3fJslpUmJ9Ff\nAn7h+OxJkh4NfDgintqM128WX7PNrJPVe92uZ9nvGyW9DPg3lk+p5H7S1rDFO+6j5+GnEEdmH2yJ\n3rSRxTvugwuzjs4s934P+JSku0kG/P0gXvHVzCwT9STRl6b3b11SFoBn6LBVVZsEfXFqmp5TN6LT\nNp3YLiJyNWq4yLKeuN5WFxE3SnoMcC5JEv31iCjuNARmZhk6aRIdEf4Lag2rOQn6YLK0c70LcVj7\n5GHieludpEHgN4AfI2nM2CPpbyNiNtvIzMyKp56WaCQ9DngCMHi8LCI+0KqgrPPVWuUuJOL4lDSl\nJKHO26jhoir6ypsd4v3AYeCv0scvAv4B+IXMIjIzK6iTJtGSfh8YBx4HfBJ4HvBZwEm01bQ4NY2G\nNywvLPXD4WNs3Lk996OGi6jWMXNXm1w5d8VMHJ+SlJ9lyMzMCqSeluhfIpkC6UsR8ZJ0XtG/a21Y\n1ul6twwnqxFW6bZR2rbVSXMOrXbMLDe+LOkZEfEFAElPBz6XcUxmZoVUz2IrxyJiEViQdArwXaDu\nZWatmPIwCbo1xsesIzwd+Lykb0v6NnAT8BOSvirp1mxDMzMrlnpaor8s6VTgamAvyRLgX2ppVNbx\nStu2grttdBQfs46wI+sAzMwsUc/sHL+W/vguSZ8EhiPCSXQbdeq0Y1l02zixctVMGQ155apGuatN\nvkXEdyQ9lQdn5/icr8dmxdapOUI3qKc7B5IukfTmiLgLOCjJWUmbHJ92rHJoZtm0Y+X9B7IOLXeO\nr4YY5Xno7yXK8xzbfQtHrtuXdWhmTSHp/wGuAR4OPAJ4bzr428wKyDlCtk6aREv6a+DZwIvToqPA\n37YyKHvQ0mnHJCX3A33MTnhA/kqz109CTw/q60E9Qn090NOTlJt1hxcBT4uIt0TEW4BnADszjsnM\nMuIcIVv1tEQ/M+3SMQsQEfcDA6vvYs2yODWdTA23lKcdqypmytCj5YU9Io55QTfrGt9myXz9QAn4\nZjahmFnWnCNkq54kel5SD0n/OyQ9HKi0NCo7oXfLcLLC31KedqwqDZWgEssLK4E2lLIJyKz5ysB+\nSe+T9F7gNuCIpL+U9JcZx2ZmbeYcIVs1BxZK6ouIBeBdwEeAEUlvBX4ReGub4iuUaoMDBsdHk6WX\nwSv8ncTgjtGkT/QCSYt0JaBSYXCHPyvrGrvT23GfzigOM8sB5wjZWm12jluAp0bE+yXtA54LCPiF\niLitLdEVyPHBARroWzY4YOPO7V7hr07HZ+GYvX6SOFZGGzw7h3WdfwJ+mOSbwW9GxGzG8ZhZhjw1\nabZWS6JPdC6NiP3A/taHU1xLBwcAJ1aNm52YZPPrLvIvRJ02XXiek2brOpL6gD8CXgZ8h6Qr3plp\nl443R8T8avubWffy1KTZWS2JHpH0+lpPRsQVLYinsBanptHwhuWFHhxgZol3AKcA50TEYQBJw8Cf\nprfXZBibmVkhrZZE9wKbWNIiba3Tu2WYyqGZEy3QgAcHmNlxFwGPjYgTI2cjYlrSrwNfx0m0mVnb\nrZZE3xcRb2tbJAXnwQFmtopYmkAvKVyU9JByMzNrvdWmuHMLdBuVtm1l487t9GweIg4fo2fzEBt3\nbnc/JzMD+JqkX1lZKOnFJC3RZmbWZqu1RD+nbVEY4MEBZlbTq4GPSnoZsI9kdo6nARuAi7MMzMys\nqGom0enKhGZmlrGI+C/g6ZIuALaRfFP4iYi4MdvIzMyKa7WWaDMzy5GI+A/gP7KOw8zM6lv228zM\nzMzMlnASbWZmZmbWIHfnMDMzW4Py/gPJcstT0/Ru6Zzllo9ct4/Z6yeJmTIaKjG4Y9QrvRZcp57L\nWXNLtJmZWYPK+w9wdNceKodm0PAGKodmOLprD+X9B7IObVVHrtvHsd23EOV56O8lyvMc230LR67b\nl3VolpFOPZfzwC3Rtm7+D9bMimZ2YhIN9KHjq8ym97MTk7m+/s1ePwk9PagvbUPrEbGQlLs1upg6\n9VzOA7dE27r4P1gzK6LFqelkddmlSv0sHpzOJqA6xUwZelaspdYj4lg5m4Asc516LueBk2hbl6X/\nwUpK7gf6mJ2YzDo0M7OW6d0yDOX55YXleXpHhrMJqE4aKkFlxUrxlUAbStkEZJnr1HM5D5xEd5ny\n/gMceufHuP/yD3DonR9reYuw/4M1syIaHB8l5haI2TkiIrmfW2BwfDTr0FY1uGMUKhVioUJUglio\nQKWSlFshdeq5nAeZJdGSeiV9WdLHsoqh22TRtcL/wZpZEZW2bWXjzu30bB4iDh+jZ/MQG3duz30f\n0k0XnseGi89HpX5YWESlfjZcfL77QxdYp57LeZDlwMLXALcDzraaJIvBAYPjoxzdtSd5UOqH8rz/\ng20xD+S0RknaCrwf+AGgAlwZEX8h6R3AzwBzwDeBl0bEA1X2/zZwGFgEFiJirF2x51lp29aO/N3b\ndOF5TpptmU49l7OWSUu0pDOBC4H3ZPH+3SqLrhX+D7a9PJDT1mgB+J2IeDzwDODVkp4A3AA8MSKe\nBNwBXL7Kazw7Ip7sBNrMLJFVS/SfA/8TOCWj9+9KvVuGqRyaOdECDbSla4X/g20fT0VkaxER9wH3\npT8flnQ7cEZETCzZ7AvAz2cRn5lZJ2p7S7Ski4CpiFh1ZndJl0naK2nvwYMH2xRdZ/PggO7ngZy2\nXpLOBp4C3LziqZcBn6ixWwATkvZJuqx10ZmZdY4sunM8C/jZtI/dh4ALJP3jyo0i4sqIGIuIsZGR\nkXbH2JHctaL7eSCnrYekTcBHgNdGxPSS8jeTdPnYVWPXZ0XEU4GfJukK8uNVXtsNH2ZWKG3vzhER\nl5P2u5P0k8DvRsSL2x1Ht2pl1woPaMueB3LaWknqJ0mgd0XER5eUXwpcBDwnIqLavhFxb3o/JWk3\ncD7wmRXbXAlcCTA2Nlb1dczMuonniba6eEBbPvjbBlsLSQKuAm6PiCuWlO8A3gD8bETM1Nh3o6RT\njv8MjAO3tT5qM7N8y3KKOyLi08Cns4zB6uMBbfnhgZy2Bs8CXgJ8VdJX0rI3AX8JlIAbkjybL0TE\nqyQ9CnhPRDwfeCSwO32+D/hARFzf7gqYmeVNpkm0dY7FqWk0vGF5oQe0mXWEiPgsoCpPfbzG9vcC\nz09/vhtwfyEzsxWcRFtdspo+z8zMiqeRMTger2MrteuccJ9oq4unzzMzs3ZoZAyOx+vYSu08J5xE\nW108oM3MzNph6RgcScn9QB+zE5Pr2taKoZ3nhLtzWN08oM3MzFqtkTE4Hq9jK7XznHBLtJmZmeVG\nI4tKeQEqW6md54STaDMzM8uNRsbgeLyOrdTOc8JJtJmZmeVGI2NwPF7HVmrnOeE+0WZmZpYrjYzB\n8XgdW6ld54Rbos3MzMzMGuQk2szMzMysQe7OYW3n1aXMzMys07kl2trKq0uZmZlZN3ASbW3l1aXM\nzMysGziJtrZanJqGUv/yQq8uZWZmZh3GSbS1lVeXMjMzs27gJNrayqtLmZmZWTfw7BzWVqVtW2Hn\n9mR2joPT9I54dg4zax3PBtT9ah1jH3trNSfR1nZeXcrM2uH4bEAa6Fs2GxBeFrpr1DrG8886l7nP\nfcPH3lrK3TnMzKwreTag7lfzGF/vY2+t5yTazMy6kmcD6n61jnHMlH3sreWcRJuZWVfybEDdr9Yx\n1lDJx95azkm0mZl1Jc8G1P1qHuMdPvbWeh5YaOvmEdBmlkeeDaj7rXaMy2dv8bG3lnISbevi0e9m\nlmeeDaj71TrGPvbWau7OYevi0e9mZmZWRE6ibV08+t3MzMyKyEm0rYtHv5uZmVkRdWWfaA90a5/B\n8dGkDzQkLdLleY+ANjMzs67XdS3Rxwe6VQ7NLBvoVt5/IOvQulJp21Y27txOz+Yh4vAxejYPsdGD\nCs3MzKzLdV1L9NKBbgCk97MTk07sWsQjoM3MzKxoui6JXpyaRsMblhc2caCbu4qYmZmZWdd152jl\nQDd3FTEzMzMz6MIkupXLvHpOZDPrRJK2SvqUpNsl7Zf0mrT8YZJukHRnen9ajf0vTbe5U9Kl7Y3e\nzCyfuq47RyuXeW11VxEzsxZZAH4nIr4k6RRgn6QbgF8FboyIt0t6I/BG4A1Ld5T0MOAtwBgQ6b7X\nRsR/t7UGlhl3Y7T16Obzp+uSaGjdQLfeLcNUDs2cGKwIeE5kM8u9iLgPuC/9+bCk24EzgBcAP5lu\ndg3waVYk0cDzgBsi4n6ANPneAXyw5YFb5o53Y9RA37JujHgWJqtDt58/Xdedo5Va2VXEzKwdJJ0N\nPAW4GXhkmmAfT7S3VNnlDGDpwI970jIrAHdjtPXo9vPHSXQDPCeymXUySZuAjwCvjYh6+6GpSllU\nee3LJO2VtPfgwYPrCdNyZHFqOllIayl3Y7Q6dfv505XdOVrJcyKbWSeS1E+SQO+KiI+mxd+TdHpE\n3CfpdGCqyq738GCXD4AzSbp9LBMRVwJXAoyNjT0kybbO5G6Mth7dfv60vSW61ihxMzNrDUkCrgJu\nj4grljx1LXB8to1LgX+tsvsngXFJp6Wzd4ynZVYA7sZo69Ht508W3TmOjxJ/PPAM4NWSnpBBHGZm\nRfEs4CXABZK+kt6eD7wd+ClJdwI/lT5G0pik9wCkAwr/F/DF9Pa244MMrfu5G6OtR7efP23vzrHK\nKPGvtTsWM7MiiIjPUr1vM8Bzqmy/F3jFksdXA1e3JjrLO3djtPXo5vMn04GFK0aJm5mZmZl1hMyS\n6JONEvdIbzMzMzPLq0yS6BqjxJeJiCsjYiwixkZGRtoboJmZmZnZKrKYnaPWKHEzMzMzs46QRUt0\nrVHiZmZmZmYdIYvZOVYbJW7WdOX9B5idmGRxapreLcMMjo+uOlK40e3NzMyseLzst3W18v4DHN21\nh8qhGTS8gcqhGY7u2kN5/4GmbG9mZmbF5CTautrsxCQa6EODA0hK7gf6mJ2YbMr2ZmZmVkxOoq2r\nLU5NQ6l/eWGpn8WDD5lVcU3bm5mZWTE5ibau1rtlGMrzywvL8/SODDdlezMzMysmJ9HW1QbHR4m5\nBWJ2johI7ucWGBwfbcr2ZmZmVkxOoq2rlbZtZePO7fRsHiIOH6Nn8xAbd26vOdtGo9ubmZlZMbV9\nijuzditt29pQEtzo9mZmZlY8bok2MzMzM2uQk2gzMzMzswY5iTYzMzMza5CTaDMzMzOzBjmJNjMz\nMzNrkJNoMzMzM7MGOYk2MzMzM2uQk2gzMzMzswY5iTYzMzMza5CTaDMzMzOzBjmJNjMzMzNrkJNo\nMzMzM7MG9WUdgOVTef8BZicmWZyapnfLMIPjo5S2bc06LDMzs7r475i1mlui7SHK+w9wdNceKodm\n0PAGKodmOLprD+X9B7IOzczM7KT8d8zawUm0PcTsxCQa6EODA0hK7gf6mJ2YzDo0MzOzk/LfMWsH\nJ9H2EItT01DqX15Y6mfx4HQ2AZmZmTXAf8esHZxE20P0bhmG8vzywvI8vSPD2QRkZmbWAP8ds3Zw\nEm0PMTg+SswtELNzRERyP7fA4Pho1qGZmZmdlP+OWTs4ibaHKG3bysad2+nZPEQcPkbP5iE27tzu\nUc1mZtYR/HfM2sFT3FlVpW1bfbEx6xKSrgYuAqYi4olp2T8B56abnAo8EBFPrrLvt4HDwCKwEBFj\nbQnabJ38d8xazUm0mVn3ex/w18D7jxdExC8d/1nSnwGHVtn/2RHx/ZZFZ2bWgZxEm5l1uYj4jKSz\nqz0nScAvAhe0MyYzs07nPtFmZsW2HfheRNxZ4/kAJiTtk3RZG+MyM8s1t0SbmRXbi4APrvL8syLi\nXklbgBskfT0iPrNyozTBvgzgrLPOak2kZmY54pZoM7OCktQH/BzwT7W2iYh70/spYDdwfo3troyI\nsYgYGxkZaUW4Zma54iTazKy4ngt8PSLuqfakpI2STjn+MzAO3NbG+MzMcstJtJlZl5P0QeAm4FxJ\n90h6efrUJazoyiHpUZI+nj58JPBZSZPALcB1EXF9u+I2M8sz94k2M+tyEfGiGuW/WqXsXuD56c93\nA17izcysCrdEm5mZmZk1yEm0mZmZmVmDFBFZx3BSkg4C32niSz4C6PbVt4pQRyhGPYtQR+jeev5g\nRBRqugpfs9ekCHUE17ObdHMd67pud0QS3WyS9kbEWNZxtFIR6gjFqGcR6gjFqac1rgjnRhHqCK5n\nNylCHU/G3TnMzMzMzBrkJNrMzMzMrEFFTaKvzDqANihCHaEY9SxCHaE49bTGFeHcKEIdwfXsJkWo\n46oK2SfazMzMzGw9itoSbWZmZma2ZoVJoiW9Q9LXJd0qabekU5c8d7mkuyR9Q9LzsoxzvST9gqT9\nkiqSxlY810313JHW4y5Jb8w6nmaRdLWkKUm3LSl7mKQbJN2Z3p+WZYzNIGmrpE9Juj09X1+Tlndd\nXW1tfM3urnqCr9tZxrhevmZXV5gkGrgBeGJEPAm4A7gcQNITgEuAbcAO4G8k9WYW5frdBvwc8Jml\nhd1UzzTudwE/DTwBeFFav27wPpLjs9QbgRsj4jHAjenjTrcA/E5EPB54BvDq9Bh2Y11tbXzN7qJ6\n+rrd8dcyX7OrKEwSHRETEbGQPvwCcGb68wuAD0VEOSK+BdwFnJ9FjM0QEbdHxDeqPNVN9TwfuCsi\n7o6IOeBDJPXreBHxGeD+FcUvAK5Jf74GeGFbg2qBiLgvIr6U/nwYuB04gy6sq62Nr9ndVU983e7o\na5mv2dUVJole4WXAJ9KfzwAOLHnunrSs23RTPbupLvV4ZETcB8mFDNiScTxNJels4CnAzXR5XW3N\nfM3u/Hp2W31OpmuvZb5mP6gv6wCaSdK/Az9Q5ak3R8S/ptu8meRriV3Hd6uyfa6nLKmnntV2q1KW\n63quopvqUmiSNgEfAV4bEdNStUNr3crX7MJcs6H76lNIvmYv11VJdEQ8d7XnJV0KXAQ8Jx6c2+8e\nYOuSzc4E7m1NhM1xsnrW0HH1XEU31aUe35N0ekTcJ+l0YCrrgJpBUj/JxXhXRHw0Le7Kulp1vmav\nquPqeRLdVp+T6bprma/ZD1WY7hySdgBvAH42ImaWPHUtcImkkqRzgMcAt2QRY4t1Uz2/CDxG0jmS\nBkgG31ybcUytdC1wafrzpUCtlquOoaT54irg9oi4YslTXVdXWxtfs7uunr5udzBfs6srzGIrku4C\nSsD/TYu+EBGvSp97M0mfuwWSryj+//buLcTKKozD+PNPCQulLrQoyYRIiw6KoiFIZYhBN+FFRBQo\nUV7URVcRVBBBFhFBIGhGFFIRVheBQWQF0hHSPFJZWXQAI5UIMcqyebvYa8iG6bDVdM/s5wcDw1pr\n1vr2d/HOy/utb69Xh5+l9yVZDKwAJgE/Alur6urWN5o+5zXAY8AY4KmqWn6CL+mYSPI8cCUwEfge\nuA94GXgBmAJ8A1xXVUNfYhlRkswH3gZ2AAOt+W46e+xG1WfVkTFmj67PCcbtkRzLjNnD65skWpIk\nSTpW+mY7hyRJknSsmERLkiRJXTKJliRJkrpkEi1JkiR1ySRakiRJ6pJJtHpeknuSfJRke5KtSS47\njmuPT7IqyRdJtiT5MMmtx2t9SRppjNnqF6PqxEKNPknm0TmxbFZVHUwyETj5KOccW1WH/uPwJ4Ev\ngfOraiDJJDrf2ypJGhYfVlEAAAKgSURBVMKYrX5iJVq97ixgX1UdBKiqfVW1GyDJnCTvJdmW5IMk\nE5KMS/J0kh2tCrGgjV2a5MUk64D1re3OJBtbteT+oQsnOQ+YC9xbVQNt/b1V9XDrH5/kzSSb23rX\ntvapSXYmWdPmfinJqf//rZKkE86Yrb5hEq1etx44J8lnSVYmuQKgHRu7FrijqmYAC4GfgdsBquoS\n4AZgTZJxba55wJKquirJIjrH6M4FZgKzk1w+ZO2LgG2DwXgYvwCLq2oWsAB4tB2NCjAdeKKqLgX2\nA7cd3W2QpBHBmK2+YRKtnlZVB4DZwDJgL7A2yVI6Ae+7qtrYxu1vj/vmA8+0tp3A18C0Nt3rhx1H\nuqj9bAE2AxfQCdB/q+3z25pk92AT8GCS7cAbwGTgzNb3bVW9235/tl2XJI1qxmz1E/dEq+dV1e/A\nBmBDkh3AEjpBdLgz6zNM26Cfhox7qKpW/8P4j4EZSU6qqoGqWg4sT3Kg9d8ITAJmV9VvSb4CBiso\nQ69tuGuVpFHHmK1+YSVaPS3J9CSHVxtm0qlU7ATOTjKnjZuQZCzwFp1ASZJpwBTg02Gmfg24Ocn4\nNnZykjMOH1BVu4BNwANJxrRx4/gz6J8G7GnBeAFw7mF/PqW9YAOdR5TvHNENkKQRxJitfmIlWr1u\nPLAiyenAIWAXsKyqfk1yfes7hc7euoXASuDxVv04BCxtb4j/ZdKqWp/kQuD91ncAuAnYM2T9W4BH\ngF1Jfmjr3NX6ngPWJdkEbKXzT2LQJ8CSJKuBz4FVR38rJKnnGbPVN1LlEwvpWEoyFXilqi4+wZci\nSfoXxmwdKbdzSJIkSV2yEi1JkiR1yUq0JEmS1CWTaEmSJKlLJtGSJElSl0yiJUmSpC6ZREuSJEld\nMomWJEmSuvQHtd8rBIm5nIMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25c6912f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (12, 6)) \n",
    "ax[0].scatter(NCAA['Score_Gap'], NCAA[\"BPI_DEF_1\"], color = \"#ea5f94\", alpha = 0.75) \n",
    "ax[1].scatter(NCAA['Score_Gap'], NCAA[\"Wins_2\"], color = \"#ea5f94\", alpha = 0.75) \n",
    "ax[0].set_xlabel(\"Score Gap\")\n",
    "ax[0].set_ylabel(\"Team's Defense Rating\")\n",
    "ax[1].set_xlabel(\"Score Gap\")\n",
    "ax[1].set_ylabel(\"Opponent's Win Record\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model I run is Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.73\n",
      "CV Test Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X, y) #using default C\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(logreg, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.70\n",
      "CV Test Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "logreg_scaled = LogisticRegression().fit(X_scaled, y) #using default C\n",
    "print(\"Test set score: {:.2f}\".format(logreg_scaled.score(X_scaled, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(logreg_scaled, X_scaled, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.75\n",
      "CV Test Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': np.arange(0.1, 100, 5)} #goes from >0 to 100 (since 100 was baseline)\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid=param_grid, cv=10)\n",
    "\n",
    "grid.fit(X, y) #finding best C\n",
    "\n",
    "best_C = grid.best_params_[\"C\"] #storing best C\n",
    "\n",
    "logreg_bestC = LogisticRegression(C = best_C).fit(X, y) #using optimal C\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(logreg_bestC.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(logreg_bestC, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base logit model has as good a CV test score as any of its 'optimized' iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model I try is K-Nearest Neighbors, using grid search to find the optimal value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.768\n",
      "best parameters: {'n_neighbors': 7}\n",
      "Test set score: 0.857\n",
      "CV Test Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 30, 2)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X, y)\n",
    "\n",
    "best_k = grid.best_params_[\"n_neighbors\"] #storing best K\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = best_k).fit(X, y)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Test set score: {:.3f}\".format(grid.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(knn, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized KNN model improves on the Logit's test score by 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now turn to tree models, starting with a simple Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 1.000\n",
      "CV Test Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_basic = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(tree_basic.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format(np.mean(cross_val_score(tree_basic, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 1.000\n",
      "CV Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_rfc = RandomForestClassifier(n_estimators=200).fit(X, y)\n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(tree_rfc.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format(np.mean(cross_val_score(tree_rfc, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 1.000\n",
      "CV Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier() #Need to instantiate a model type for bagging first\n",
    "tree_bag = BaggingClassifier(tree, n_estimators=100, \n",
    "                        random_state=1).fit(X, y)\n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(tree_bag.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format(np.mean(cross_val_score(tree_bag, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these tree models improves on the KNN's score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do take advantage of the tree models to look at the contribution of my independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53014213  0.46985787]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['BPI_DEF_1', 'Wins_2'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tree_rfc.feature_importances_) \n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They seem to contribute about equally to the model's predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model I run is a Support Vector Machine. I first run a linear version, tuning its parameters, then a non-linear SVM. The parameter tuning of the non-linear SVM is somewhat limited because the code always runs very slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.750\n",
      "best parameters: {'C': 1}\n",
      "Test set score: 0.750\n",
      "CV Test Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "param_grid = {'C': np.arange(1, 600, 20)}\n",
    "grid = GridSearchCV(SVC(kernel = \"linear\"), param_grid=param_grid, cv=10)\n",
    "grid.fit(X, y)\n",
    "\n",
    "best_C = grid.best_params_[\"C\"] #storing best C\n",
    "\n",
    "svc_linear = SVC(kernel = \"linear\", C = best_C).fit(X, y)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Test set score: {:.3f}\".format(grid.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(svc_linear, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.821\n",
      "best parameters: {'C': 141, 'gamma': 0.015}\n",
      "Test set score: 0.893\n",
      "CV Test Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': np.arange(1, 600, 10), \n",
    "             'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.015, 0.5]} #manual bc otherwise very slow\n",
    "grid = GridSearchCV(SVC(kernel = \"rbf\", gamma = 0.001), param_grid=param_grid, cv=10)\n",
    "grid.fit(X, y)\n",
    "\n",
    "best_C = grid.best_params_[\"C\"]\n",
    "\n",
    "svc = SVC(kernel = \"rbf\", C = best_C, gamma = 0.001).fit(X, y)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Test set score: {:.3f}\".format(grid.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(svc, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this approach is that the GridSearch picks the best **Test** set score. Playing around with values manually actually yields better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.875\n",
      "CV Test Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = \"rbf\", C = 600, gamma = 0.01).fit(X, y)\n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(svc.score(X, y)))\n",
    "print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(svc, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below optimizes the SVC based on test score instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 291\n",
      "Best CV Test Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in np.arange(1, 600, 10): \n",
    "    model = SVC(kernel = \"rbf\", C = i, gamma = 0.01).fit(X, y)\n",
    "    cv_score = np.mean(cross_val_score(model, X, y, cv=10))\n",
    "    scores.append(cv_score)\n",
    "    \n",
    "scores.index(max(scores)) #finding position of max\n",
    "print(\"Optimal C: {}\".format(np.arange(1, 600, 10)[scores.index(max(scores))])) #finding optimal value of C\n",
    "print(\"Best CV Test Score: {}\".format(round(max(scores), 2))) #finding best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized SVC improves on our previous best test score by 5%. It is therefore the model I keep for prediction purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset below contains all of the same information as our training set, updated for 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team_1</th>\n",
       "      <th>Team_2</th>\n",
       "      <th>RK_1</th>\n",
       "      <th>CONF_1</th>\n",
       "      <th>W-L_1</th>\n",
       "      <th>BPI_OFF_1</th>\n",
       "      <th>BPI_DEF_1</th>\n",
       "      <th>BPI_1</th>\n",
       "      <th>7-DAY_RK CHG_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Luck_2</th>\n",
       "      <th>X13_2</th>\n",
       "      <th>AdjEM_1_2</th>\n",
       "      <th>X15_2</th>\n",
       "      <th>OppO_2</th>\n",
       "      <th>X17_2</th>\n",
       "      <th>OppD_2</th>\n",
       "      <th>X19_2</th>\n",
       "      <th>AdjEM_2_2_2</th>\n",
       "      <th>X21_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>3</td>\n",
       "      <td>ACC</td>\n",
       "      <td>31-5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011</td>\n",
       "      <td>156</td>\n",
       "      <td>8.07</td>\n",
       "      <td>53</td>\n",
       "      <td>108.1</td>\n",
       "      <td>54</td>\n",
       "      <td>100.1</td>\n",
       "      <td>44</td>\n",
       "      <td>-6.12</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LSU</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>20</td>\n",
       "      <td>SEC</td>\n",
       "      <td>28-6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>196</td>\n",
       "      <td>12.87</td>\n",
       "      <td>4</td>\n",
       "      <td>110.2</td>\n",
       "      <td>13</td>\n",
       "      <td>97.4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.15</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>1</td>\n",
       "      <td>ACC</td>\n",
       "      <td>31-3</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>268</td>\n",
       "      <td>4.91</td>\n",
       "      <td>70</td>\n",
       "      <td>107.5</td>\n",
       "      <td>64</td>\n",
       "      <td>102.6</td>\n",
       "      <td>87</td>\n",
       "      <td>0.36</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>9</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>25-9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>68</td>\n",
       "      <td>10.18</td>\n",
       "      <td>27</td>\n",
       "      <td>109.5</td>\n",
       "      <td>27</td>\n",
       "      <td>99.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.96</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Florida State</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>14</td>\n",
       "      <td>ACC</td>\n",
       "      <td>29-7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009</td>\n",
       "      <td>162</td>\n",
       "      <td>3.40</td>\n",
       "      <td>85</td>\n",
       "      <td>106.7</td>\n",
       "      <td>75</td>\n",
       "      <td>103.3</td>\n",
       "      <td>104</td>\n",
       "      <td>1.98</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Team_1          Team_2  RK_1   CONF_1 W-L_1  BPI_OFF_1  \\\n",
       "0           1           Duke   Virginia Tech     3      ACC  31-5       10.9   \n",
       "1           2            LSU  Michigan State    20      SEC  28-6        8.5   \n",
       "2           3       Virginia          Oregon     1      ACC  31-3       11.8   \n",
       "3           4         Purdue       Tennessee     9  Big Ten  25-9       11.0   \n",
       "4           5  Florida State         Gonzaga    14      ACC  29-7        6.3   \n",
       "\n",
       "   BPI_DEF_1  BPI_1 7-DAY_RK CHG_1  ...    Luck_2  X13_2  AdjEM_1_2 X15_2  \\\n",
       "0       10.6   21.5             --  ...     0.011    156       8.07    53   \n",
       "1        4.4   12.9              3  ...    -0.006    196      12.87     4   \n",
       "2       11.6   23.4             --  ...    -0.038    268       4.91    70   \n",
       "3        6.4   17.4              1  ...     0.047     68      10.18    27   \n",
       "4        8.5   14.8              2  ...     0.009    162       3.40    85   \n",
       "\n",
       "  OppO_2  X17_2  OppD_2  X19_2 AdjEM_2_2_2  X21_2  \n",
       "0  108.1     54   100.1     44       -6.12    325  \n",
       "1  110.2     13    97.4      5        3.15     87  \n",
       "2  107.5     64   102.6     87        0.36    153  \n",
       "3  109.5     27    99.3     30        0.96    131  \n",
       "4  106.7     75   103.3    104        1.98    102  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCAA_19 = pd.read_csv(r\"C:/Users/ia767/Documents/NCAA_big_19.csv\")\n",
    "NCAA_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC(kernel = \"rbf\", C = 291, gamma = 0.01).fit(X, y).predict(NCAA_19[[\"BPI_DEF_1\", \"Wins_2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This yields my predictions for the upcoming games. The output is \"1\" if team 1 is predicted to win and 0 otherwise. That is: Duke will win against VT, LSU against Michigan State, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_1</th>\n",
       "      <th>Team_2</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duke</td>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSU</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Purdue</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Florida State</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Team_1          Team_2  preds\n",
       "0           Duke   Virginia Tech      1\n",
       "1            LSU  Michigan State      1\n",
       "2       Virginia          Oregon      1\n",
       "3         Purdue       Tennessee      0\n",
       "4  Florida State         Gonzaga      0\n",
       "5     Texas Tech        Michigan      1\n",
       "6        Houston        Kentucky      1\n",
       "7         Auburn  North Carolina      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCAA_19[\"preds\"] = SVC(kernel = \"rbf\", C = 291, gamma = 0.01).fit(X, y).predict(NCAA_19[[\"BPI_DEF_1\", \"Wins_2\"]])\n",
    "NCAA_19[[\"Team_1\", 'Team_2', \"preds\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which variables could I add to the model to improve my prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use correlation with our dependent variable as a selection criterion. I also choose variables with low correlation with my current dependent variables to make sure they will contribute to my prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Win</th>\n",
       "      <th>BPI_DEF_1</th>\n",
       "      <th>Wins_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0.201331</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>-0.042503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_Gap</th>\n",
       "      <td>0.784962</td>\n",
       "      <td>0.306255</td>\n",
       "      <td>-0.259920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Win</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267286</td>\n",
       "      <td>-0.302102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wins_1</th>\n",
       "      <td>0.349615</td>\n",
       "      <td>0.346597</td>\n",
       "      <td>0.037474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdjEM_1_1_1</th>\n",
       "      <td>0.210072</td>\n",
       "      <td>0.303083</td>\n",
       "      <td>-0.142803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OppD_1</th>\n",
       "      <td>-0.228382</td>\n",
       "      <td>-0.218900</td>\n",
       "      <td>0.118188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X19_1</th>\n",
       "      <td>-0.241566</td>\n",
       "      <td>-0.272801</td>\n",
       "      <td>0.105683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luck_2</th>\n",
       "      <td>-0.241174</td>\n",
       "      <td>0.137012</td>\n",
       "      <td>0.154525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13_2</th>\n",
       "      <td>0.229904</td>\n",
       "      <td>-0.091662</td>\n",
       "      <td>-0.186480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdjEM_2_2_2</th>\n",
       "      <td>0.298900</td>\n",
       "      <td>0.122751</td>\n",
       "      <td>-0.099345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21_2</th>\n",
       "      <td>-0.287844</td>\n",
       "      <td>-0.113268</td>\n",
       "      <td>0.137406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Win  BPI_DEF_1    Wins_2\n",
       "Unnamed: 0   0.201331   0.157051 -0.042503\n",
       "Score_Gap    0.784962   0.306255 -0.259920\n",
       "Win          1.000000   0.267286 -0.302102\n",
       "Wins_1       0.349615   0.346597  0.037474\n",
       "AdjEM_1_1_1  0.210072   0.303083 -0.142803\n",
       "OppD_1      -0.228382  -0.218900  0.118188\n",
       "X19_1       -0.241566  -0.272801  0.105683\n",
       "Luck_2      -0.241174   0.137012  0.154525\n",
       "X13_2        0.229904  -0.091662 -0.186480\n",
       "AdjEM_2_2_2  0.298900   0.122751 -0.099345\n",
       "X21_2       -0.287844  -0.113268  0.137406"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCAA.corr()[[\"Win\", \"BPI_DEF_1\", \"Wins_2\"]][(abs(NCAA.corr()[\"Win\"]) > abs(0.2)) & (abs(NCAA.corr()[\"BPI_DEF_1\"]) < abs(0.35))\n",
    "                                           & (abs(NCAA.corr()[\"Wins_2\"]) < abs(0.35))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us quite a bit of choice when it comes to our new variables. The code below finds the new test CV for the selected non-linear model for every one of these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new variables I'm considering are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AdjEM_1_1_1', 'OppD_1', 'X19_1', 'Luck_2', 'X13_2', 'AdjEM_2_2_2',\n",
       "       'X21_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCAA.corr()[[\"Win\", \"BPI_DEF_1\", \"Wins_2\"]][(abs(NCAA.corr()[\"Win\"]) > abs(0.2)) & (abs(NCAA.corr()[\"BPI_DEF_1\"]) < abs(0.35))\n",
    "                                           & (abs(NCAA.corr()[\"Wins_2\"]) < abs(0.35))].index[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdjEM_1_1_1\n",
      "CV Test Score: 0.76\n",
      "OppD_1\n",
      "CV Test Score: 0.73\n",
      "X19_1\n",
      "CV Test Score: 0.68\n",
      "Luck_2\n",
      "CV Test Score: 0.80\n",
      "X13_2\n",
      "CV Test Score: 0.52\n",
      "AdjEM_2_2_2\n",
      "CV Test Score: 0.76\n",
      "X21_2\n",
      "CV Test Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "x = NCAA.corr()[[\"Win\", \"BPI_DEF_1\", \"Wins_2\"]][(abs(NCAA.corr()[\"Win\"]) > abs(0.2)) & (abs(NCAA.corr()[\"BPI_DEF_1\"]) < abs(0.35))\n",
    "                                           & (abs(NCAA.corr()[\"Wins_2\"]) < abs(0.35))].index[4:] #possible variables\n",
    "initial = [\"BPI_DEF_1\", \"Wins_2\"]\n",
    "\n",
    "for i in range(0, len(x)):\n",
    "    initial = [\"BPI_DEF_1\", \"Wins_2\"]\n",
    "    initial.append(x[i])\n",
    "    X = NCAA[initial]\n",
    "    svc = SVC(kernel = \"rbf\", C = 291, gamma = 0.01).fit(X, y)\n",
    "    print(x[i])\n",
    "    print(\"CV Test Score: {:.2f}\".format( np.mean(cross_val_score(svc, X, y, cv=10))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these variables actually improve the model. It seems like Luck_2 is the 'best' of the batch, but it is essentially a residual (and might not carry over for another year), so I'll focus on AdjEM_1_1_1 & AdjEM_2_2_2 for now. (The model was tuned using a different set of variables, so maybe the 'optimized' performance will be better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 91\n",
      "Best CV Test Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "X = NCAA[[\"BPI_DEF_1\", \"Wins_2\", \"AdjEM_1_1_1\"]]\n",
    "scores = []\n",
    "\n",
    "for i in np.arange(1, 600, 10): \n",
    "    model = SVC(kernel = \"rbf\", C = i, gamma = 0.01).fit(X, y)\n",
    "    cv_score = np.mean(cross_val_score(model, X, y, cv=10))\n",
    "    scores.append(cv_score)\n",
    "    \n",
    "scores.index(max(scores)) #finding position of max\n",
    "print(\"Optimal C: {}\".format(np.arange(1, 600, 10)[scores.index(max(scores))])) #finding optimal value of C\n",
    "print(\"Best CV Test Score: {}\".format(round(max(scores), 2))) #finding best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 201\n",
      "Best CV Test Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "X = NCAA[[\"BPI_DEF_1\", \"Wins_2\", \"AdjEM_2_2_2\"]]\n",
    "scores = []\n",
    "\n",
    "for i in np.arange(1, 600, 10): \n",
    "    model = SVC(kernel = \"rbf\", C = i, gamma = 0.01).fit(X, y)\n",
    "    cv_score = np.mean(cross_val_score(model, X, y, cv=10))\n",
    "    scores.append(cv_score)\n",
    "    \n",
    "scores.index(max(scores)) #finding position of max\n",
    "print(\"Optimal C: {}\".format(np.arange(1, 600, 10)[scores.index(max(scores))])) #finding optimal value of C\n",
    "print(\"Best CV Test Score: {}\".format(round(max(scores), 2))) #finding best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither actually improves the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
